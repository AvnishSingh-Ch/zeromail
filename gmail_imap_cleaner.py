#!/usr/bin/env python3
"""
Gmail IMAP Cleaner

A Python script that connects to Gmail using IMAP to perform automated email management tasks:
1. Delete emails older than a specified date
2. Find emails containing unsubscribe links and automatically unsubscribe

Usage:
    python gmail_imap_cleaner.py

Configuration:
    Modify the configuration variables below before running the script.
    
Requirements:
    - Gmail account with "less secure apps" enabled or app password configured
    - Python 3.6+ with standard libraries only

Author: Generated by Kiro AI Assistant
License: MIT
"""

import imaplib
import email
import re
import datetime
import ssl
import requests
import logging
import time
from email.header import decode_header
from email.utils import parsedate_tz, mktime_tz

# =============================================================================
# CONFIGURATION - Modify these variables before running the script
# =============================================================================

# Gmail IMAP Configuration
EMAIL = "your.email@gmail.com"          # Your Gmail address
PASSWORD = "your_app_password_here"     # Your Gmail password or app password
CUTOFF_DATE = "01-Jul-2023"            # Delete emails older than this date (DD-MMM-YYYY format)

# IMAP Server Settings
IMAP_SERVER = "imap.gmail.com"         # Gmail IMAP server
IMAP_PORT = 993                        # SSL port for IMAP

# Processing Settings
REQUEST_DELAY = 1                      # Seconds between unsubscribe requests (to avoid rate limiting)
BATCH_SIZE = 100                       # Number of emails to process in each batch
HTTP_TIMEOUT = 10                      # Timeout for HTTP requests in seconds

# Logging Configuration
LOG_LEVEL = logging.INFO               # Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_FORMAT = '%(asctime)s - %(levelname)s - %(message)s'

# =============================================================================
# GLOBAL VARIABLES - Do not modify these
# =============================================================================

# IMAP connection object
imap_connection = None

# Operation summary counters
operation_summary = {
    'emails_deleted': 0,
    'unsubscribe_emails_found': 0,
    'unsubscribe_links_processed': 0,
    'successful_unsubscribes': 0,
    'failed_unsubscribes': 0
}

# Regex pattern for extracting unsubscribe links
UNSUBSCRIBE_REGEX = r'https?://[^\s<>"]+unsubscribe[^\s<>"]*'

# =============================================================================
# LOGGING SETUP
# =============================================================================

def setup_logging():
    """
    Configure logging for the script with appropriate format and level.
    """
    logging.basicConfig(
        level=LOG_LEVEL,
        format=LOG_FORMAT,
        handlers=[
            logging.StreamHandler(),  # Console output
        ]
    )
    
    # Reduce noise from requests library
    logging.getLogger("requests").setLevel(logging.WARNING)
    logging.getLogger("urllib3").setLevel(logging.WARNING)

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def validate_configuration():
    """
    Validate the configuration variables to ensure they are properly set.
    
    Returns:
        bool: True if configuration is valid, False otherwise
    """
    if EMAIL == "your.email@gmail.com" or not EMAIL:
        logging.error("Please set your Gmail address in the EMAIL variable")
        return False
    
    if PASSWORD == "your_app_password_here" or not PASSWORD:
        logging.error("Please set your Gmail password or app password in the PASSWORD variable")
        return False
    
    if not CUTOFF_DATE:
        logging.error("Please set the CUTOFF_DATE variable")
        return False
    
    # Validate date format
    try:
        datetime.datetime.strptime(CUTOFF_DATE, "%d-%b-%Y")
    except ValueError:
        logging.error(f"Invalid date format: {CUTOFF_DATE}. Use DD-MMM-YYYY format (e.g., 01-Jul-2023)")
        return False
    
    logging.info("Configuration validation passed")
    return True

def log_operation_summary():
    """
    Log a summary of all operations performed by the script.
    """
    logging.info("=" * 60)
    logging.info("OPERATION SUMMARY")
    logging.info("=" * 60)
    logging.info(f"Emails deleted: {operation_summary['emails_deleted']}")
    logging.info(f"Unsubscribe emails found: {operation_summary['unsubscribe_emails_found']}")
    logging.info(f"Unsubscribe links processed: {operation_summary['unsubscribe_links_processed']}")
    logging.info(f"Successful unsubscribes: {operation_summary['successful_unsubscribes']}")
    logging.info(f"Failed unsubscribes: {operation_summary['failed_unsubscribes']}")
    logging.info("=" * 60)

# =============================================================================
# IMAP CONNECTION MANAGEMENT
# =============================================================================

def connect_to_gmail():
    """
    Establish SSL IMAP connection to Gmail and authenticate.
    
    Returns:
        imaplib.IMAP4_SSL: Authenticated IMAP connection object, or None if failed
    """
    global imap_connection
    
    try:
        logging.info(f"Connecting to Gmail IMAP server: {IMAP_SERVER}:{IMAP_PORT}")
        
        # Create SSL context for secure connection
        ssl_context = ssl.create_default_context()
        
        # Establish IMAP SSL connection
        imap_connection = imaplib.IMAP4_SSL(IMAP_SERVER, IMAP_PORT, ssl_context=ssl_context)
        
        logging.info("SSL connection established successfully")
        
        # Authenticate with Gmail
        logging.info(f"Authenticating with email: {EMAIL}")
        result = imap_connection.login(EMAIL, PASSWORD)
        
        if result[0] == 'OK':
            logging.info("Authentication successful")
            
            # Select INBOX folder
            result = imap_connection.select('INBOX')
            if result[0] == 'OK':
                email_count = int(result[1][0])
                logging.info(f"INBOX selected successfully. Total emails: {email_count}")
                return imap_connection
            else:
                logging.error(f"Failed to select INBOX: {result[1]}")
                return None
        else:
            logging.error(f"Authentication failed: {result[1]}")
            return None
            
    except imaplib.IMAP4.error as e:
        logging.error(f"IMAP error during connection: {e}")
        return None
    except ssl.SSLError as e:
        logging.error(f"SSL error during connection: {e}")
        logging.error("This might indicate an issue with SSL/TLS configuration")
        return None
    except Exception as e:
        logging.error(f"Unexpected error during connection: {e}")
        return None

def disconnect_from_gmail():
    """
    Clean disconnection from Gmail IMAP server.
    
    Returns:
        bool: True if disconnection was successful, False otherwise
    """
    global imap_connection
    
    if imap_connection is None:
        logging.info("No active IMAP connection to disconnect")
        return True
    
    try:
        logging.info("Disconnecting from Gmail IMAP server")
        
        # Close the selected mailbox
        try:
            imap_connection.close()
            logging.info("Mailbox closed successfully")
        except imaplib.IMAP4.error as e:
            logging.warning(f"Error closing mailbox (continuing with logout): {e}")
        
        # Logout from the server
        imap_connection.logout()
        logging.info("Logged out from Gmail IMAP server successfully")
        
        imap_connection = None
        return True
        
    except imaplib.IMAP4.error as e:
        logging.error(f"IMAP error during disconnection: {e}")
        return False
    except Exception as e:
        logging.error(f"Unexpected error during disconnection: {e}")
        return False

def ensure_connection():
    """
    Ensure that we have an active IMAP connection, reconnect if necessary.
    
    Returns:
        bool: True if connection is active, False otherwise
    """
    global imap_connection
    
    if imap_connection is None:
        logging.info("No active connection, attempting to connect")
        return connect_to_gmail() is not None
    
    try:
        # Test the connection with a simple NOOP command
        result = imap_connection.noop()
        if result[0] == 'OK':
            return True
        else:
            logging.warning("Connection test failed, attempting to reconnect")
            disconnect_from_gmail()
            return connect_to_gmail() is not None
    except Exception as e:
        logging.warning(f"Connection test error, attempting to reconnect: {e}")
        disconnect_from_gmail()
        return connect_to_gmail() is not None

# =============================================================================
# DATE PARSING AND COMPARISON FUNCTIONS
# =============================================================================

def parse_email_date(date_string):
    """
    Parse email date string from IMAP format to datetime object.
    
    Args:
        date_string (str): Date string from email header
        
    Returns:
        datetime.datetime: Parsed datetime object, or None if parsing fails
    """
    if not date_string:
        return None
    
    try:
        # Parse the date string using email.utils.parsedate_tz
        parsed_date = parsedate_tz(date_string)
        if parsed_date:
            # Convert to timestamp and then to datetime
            timestamp = mktime_tz(parsed_date)
            return datetime.datetime.fromtimestamp(timestamp)
        else:
            logging.warning(f"Could not parse date string: {date_string}")
            return None
    except Exception as e:
        logging.warning(f"Error parsing date '{date_string}': {e}")
        return None

def parse_cutoff_date(cutoff_date_str):
    """
    Parse the cutoff date string from configuration format to datetime object.
    
    Args:
        cutoff_date_str (str): Date string in DD-MMM-YYYY format (e.g., "01-Jul-2023")
        
    Returns:
        datetime.datetime: Parsed datetime object, or None if parsing fails
    """
    try:
        return datetime.datetime.strptime(cutoff_date_str, "%d-%b-%Y")
    except ValueError as e:
        logging.error(f"Invalid cutoff date format '{cutoff_date_str}': {e}")
        return None

def is_email_older_than_cutoff(email_date, cutoff_date):
    """
    Compare email date with cutoff date to determine if email should be deleted.
    
    Args:
        email_date (datetime.datetime): Email date
        cutoff_date (datetime.datetime): Cutoff date
        
    Returns:
        bool: True if email is older than cutoff date, False otherwise
    """
    if email_date is None or cutoff_date is None:
        return False
    
    return email_date < cutoff_date

def format_date_for_imap_search(date_obj):
    """
    Format datetime object for IMAP BEFORE search command.
    
    Args:
        date_obj (datetime.datetime): Date to format
        
    Returns:
        str: Date formatted for IMAP search (DD-MMM-YYYY format)
    """
    if date_obj is None:
        return None
    
    # IMAP BEFORE command expects DD-MMM-YYYY format
    return date_obj.strftime("%d-%b-%Y")

def validate_date_format(date_string):
    """
    Validate that a date string is in the correct DD-MMM-YYYY format.
    
    Args:
        date_string (str): Date string to validate
        
    Returns:
        bool: True if format is valid, False otherwise
    """
    try:
        datetime.datetime.strptime(date_string, "%d-%b-%Y")
        return True
    except ValueError:
        return False

def get_date_range_info(cutoff_date_str):
    """
    Get information about the date range for logging purposes.
    
    Args:
        cutoff_date_str (str): Cutoff date string
        
    Returns:
        dict: Dictionary with date range information
    """
    cutoff_date = parse_cutoff_date(cutoff_date_str)
    if cutoff_date is None:
        return None
    
    now = datetime.datetime.now()
    days_difference = (now - cutoff_date).days
    
    return {
        'cutoff_date': cutoff_date,
        'cutoff_date_formatted': format_date_for_imap_search(cutoff_date),
        'current_date': now,
        'days_difference': days_difference,
        'is_future_date': days_difference < 0
    }

# =============================================================================
# DATE FUNCTION TESTS
# =============================================================================

def test_date_functions():
    """
    Basic unit tests for date parsing and comparison functions.
    
    Returns:
        bool: True if all tests pass, False otherwise
    """
    logging.info("Running date function tests...")
    
    # Test 1: Parse cutoff date
    test_cutoff = "01-Jul-2023"
    parsed_cutoff = parse_cutoff_date(test_cutoff)
    if parsed_cutoff is None:
        logging.error("Test 1 failed: Could not parse cutoff date")
        return False
    
    # Test 2: Format date for IMAP
    formatted_date = format_date_for_imap_search(parsed_cutoff)
    if formatted_date != test_cutoff:
        logging.error(f"Test 2 failed: Expected {test_cutoff}, got {formatted_date}")
        return False
    
    # Test 3: Validate date format
    if not validate_date_format("15-Dec-2022"):
        logging.error("Test 3 failed: Valid date format not recognized")
        return False
    
    if validate_date_format("2022-12-15"):
        logging.error("Test 4 failed: Invalid date format accepted")
        return False
    
    # Test 5: Parse email date
    test_email_date = "Mon, 15 Aug 2022 10:30:00 +0000"
    parsed_email_date = parse_email_date(test_email_date)
    if parsed_email_date is None:
        logging.error("Test 5 failed: Could not parse email date")
        return False
    
    # Test 6: Date comparison
    older_date = datetime.datetime(2022, 1, 1)
    newer_date = datetime.datetime(2024, 1, 1)
    cutoff = datetime.datetime(2023, 1, 1)
    
    if not is_email_older_than_cutoff(older_date, cutoff):
        logging.error("Test 6 failed: Older date not recognized as older")
        return False
    
    if is_email_older_than_cutoff(newer_date, cutoff):
        logging.error("Test 7 failed: Newer date recognized as older")
        return False
    
    logging.info("All date function tests passed!")
    return True

# =============================================================================
# EMAIL SEARCH FUNCTIONALITY
# =============================================================================

def search_old_emails(cutoff_date_str):
    """
    Search for emails older than the cutoff date using IMAP BEFORE command.
    
    Args:
        cutoff_date_str (str): Cutoff date in DD-MMM-YYYY format
        
    Returns:
        list: List of email IDs that are older than cutoff date, or empty list if none found
    """
    global imap_connection
    
    if not ensure_connection():
        logging.error("No active IMAP connection for email search")
        return []
    
    try:
        # Parse cutoff date
        cutoff_date = parse_cutoff_date(cutoff_date_str)
        if cutoff_date is None:
            logging.error("Failed to parse cutoff date for search")
            return []
        
        # Format date for IMAP search
        search_date = format_date_for_imap_search(cutoff_date)
        logging.info(f"Searching for emails before {search_date}")
        
        # Search for emails before the cutoff date
        search_criteria = f'BEFORE {search_date}'
        result, email_ids = imap_connection.search(None, search_criteria)
        
        if result != 'OK':
            logging.error(f"IMAP search failed: {email_ids}")
            return []
        
        # Parse email IDs
        if email_ids[0]:
            id_list = email_ids[0].split()
            logging.info(f"Found {len(id_list)} emails older than {cutoff_date_str}")
            return [id.decode() for id in id_list]
        else:
            logging.info(f"No emails found older than {cutoff_date_str}")
            return []
            
    except imaplib.IMAP4.error as e:
        logging.error(f"IMAP error during email search: {e}")
        return []
    except Exception as e:
        logging.error(f"Unexpected error during email search: {e}")
        return []

def get_email_metadata(email_id):
    """
    Extract metadata (subject, sender, date) from an email.
    
    Args:
        email_id (str): IMAP email ID
        
    Returns:
        dict: Dictionary with email metadata, or None if extraction fails
    """
    global imap_connection
    
    if not ensure_connection():
        logging.error("No active IMAP connection for metadata extraction")
        return None
    
    try:
        # Fetch email headers
        result, email_data = imap_connection.fetch(email_id, '(RFC822.HEADER)')
        
        if result != 'OK':
            logging.warning(f"Failed to fetch email {email_id}: {email_data}")
            return None
        
        # Parse email headers
        email_message = email.message_from_bytes(email_data[0][1])
        
        # Extract subject
        subject = email_message.get('Subject', 'No Subject')
        if subject:
            # Decode subject if it's encoded
            decoded_subject = decode_header(subject)
            subject = ''.join([
                part[0].decode(part[1] or 'utf-8') if isinstance(part[0], bytes) else part[0]
                for part in decoded_subject
            ])
        
        # Extract sender
        sender = email_message.get('From', 'Unknown Sender')
        
        # Extract and parse date
        date_str = email_message.get('Date', '')
        email_date = parse_email_date(date_str)
        
        return {
            'id': email_id,
            'subject': subject[:100] + '...' if len(subject) > 100 else subject,  # Truncate long subjects
            'from': sender,
            'date': email_date,
            'date_str': date_str
        }
        
    except Exception as e:
        logging.warning(f"Error extracting metadata for email {email_id}: {e}")
        return None

def search_emails_batch(email_ids, batch_size=None):
    """
    Process emails in batches to avoid memory issues with large inboxes.
    
    Args:
        email_ids (list): List of email IDs to process
        batch_size (int): Size of each batch (uses global BATCH_SIZE if None)
        
    Yields:
        list: Batch of email IDs
    """
    if batch_size is None:
        batch_size = BATCH_SIZE
    
    for i in range(0, len(email_ids), batch_size):
        yield email_ids[i:i + batch_size]

def log_search_results(email_ids, operation_type="search"):
    """
    Log the results of an email search operation.
    
    Args:
        email_ids (list): List of email IDs found
        operation_type (str): Type of operation for logging
    """
    count = len(email_ids)
    
    if count == 0:
        logging.info(f"No emails found for {operation_type} operation")
    elif count == 1:
        logging.info(f"Found 1 email for {operation_type} operation")
    else:
        logging.info(f"Found {count} emails for {operation_type} operation")
    
    # Log first few email IDs for debugging (if not too many)
    if count > 0 and count <= 10:
        logging.debug(f"Email IDs: {', '.join(email_ids)}")
    elif count > 10:
        logging.debug(f"First 10 email IDs: {', '.join(email_ids[:10])}")

def validate_email_ids(email_ids):
    """
    Validate that email IDs are in the correct format.
    
    Args:
        email_ids (list): List of email IDs to validate
        
    Returns:
        list: List of valid email IDs
    """
    valid_ids = []
    
    for email_id in email_ids:
        try:
            # Email IDs should be numeric strings
            int(email_id)
            valid_ids.append(email_id)
        except ValueError:
            logging.warning(f"Invalid email ID format: {email_id}")
    
    if len(valid_ids) != len(email_ids):
        logging.warning(f"Filtered {len(email_ids) - len(valid_ids)} invalid email IDs")
    
    return valid_ids

# =============================================================================
# EMAIL DELETION MECHANISM
# =============================================================================

def delete_email(email_id):
    """
    Delete a single email by marking it for deletion and expunging.
    
    Args:
        email_id (str): IMAP email ID to delete
        
    Returns:
        bool: True if deletion was successful, False otherwise
    """
    global imap_connection
    
    if not ensure_connection():
        logging.error("No active IMAP connection for email deletion")
        return False
    
    try:
        # Mark email for deletion
        result = imap_connection.store(email_id, '+FLAGS', '\\Deleted')
        
        if result[0] != 'OK':
            logging.error(f"Failed to mark email {email_id} for deletion: {result[1]}")
            return False
        
        logging.debug(f"Email {email_id} marked for deletion")
        return True
        
    except imaplib.IMAP4.error as e:
        logging.error(f"IMAP error deleting email {email_id}: {e}")
        return False
    except Exception as e:
        logging.error(f"Unexpected error deleting email {email_id}: {e}")
        return False

def delete_emails_batch(email_ids):
    """
    Delete multiple emails in a batch operation.
    
    Args:
        email_ids (list): List of email IDs to delete
        
    Returns:
        dict: Dictionary with deletion results
    """
    results = {
        'successful': [],
        'failed': [],
        'total': len(email_ids)
    }
    
    if not email_ids:
        logging.info("No emails to delete")
        return results
    
    logging.info(f"Starting deletion of {len(email_ids)} emails")
    
    for email_id in email_ids:
        if delete_email(email_id):
            results['successful'].append(email_id)
        else:
            results['failed'].append(email_id)
    
    # Log batch results
    logging.info(f"Batch deletion completed: {len(results['successful'])} successful, {len(results['failed'])} failed")
    
    return results

def expunge_deleted_emails():
    """
    Permanently remove emails marked for deletion from the server.
    
    Returns:
        bool: True if expunge was successful, False otherwise
    """
    global imap_connection
    
    if not ensure_connection():
        logging.error("No active IMAP connection for expunge operation")
        return False
    
    try:
        logging.info("Expunging deleted emails from server...")
        result = imap_connection.expunge()
        
        if result[0] == 'OK':
            # Count expunged emails
            expunged_count = len([r for r in result[1] if r])
            logging.info(f"Successfully expunged {expunged_count} emails from server")
            return True
        else:
            logging.error(f"Expunge operation failed: {result[1]}")
            return False
            
    except imaplib.IMAP4.error as e:
        logging.error(f"IMAP error during expunge: {e}")
        return False
    except Exception as e:
        logging.error(f"Unexpected error during expunge: {e}")
        return False

def delete_old_emails_with_logging(cutoff_date_str):
    """
    Complete workflow to search, log, and delete old emails.
    
    Args:
        cutoff_date_str (str): Cutoff date in DD-MMM-YYYY format
        
    Returns:
        int: Number of emails successfully deleted
    """
    global operation_summary
    
    logging.info("=" * 50)
    logging.info("STARTING OLD EMAIL DELETION PROCESS")
    logging.info("=" * 50)
    
    # Search for old emails
    old_email_ids = search_old_emails(cutoff_date_str)
    
    if not old_email_ids:
        logging.info("No old emails found to delete")
        return 0
    
    # Validate email IDs
    valid_email_ids = validate_email_ids(old_email_ids)
    
    if not valid_email_ids:
        logging.warning("No valid email IDs found for deletion")
        return 0
    
    # Log details of emails to be deleted
    deleted_count = 0
    
    for batch in search_emails_batch(valid_email_ids):
        logging.info(f"Processing batch of {len(batch)} emails for deletion")
        
        for email_id in batch:
            # Get email metadata for logging
            metadata = get_email_metadata(email_id)
            
            if metadata:
                logging.info(f"Deleting email {email_id}: '{metadata['subject']}' from {metadata['from']} ({metadata['date_str']})")
            else:
                logging.info(f"Deleting email {email_id} (metadata unavailable)")
            
            # Delete the email
            if delete_email(email_id):
                deleted_count += 1
                operation_summary['emails_deleted'] += 1
            else:
                logging.error(f"Failed to delete email {email_id}")
    
    # Expunge deleted emails
    if deleted_count > 0:
        if expunge_deleted_emails():
            logging.info(f"Successfully deleted and expunged {deleted_count} old emails")
        else:
            logging.warning(f"Emails marked for deletion but expunge failed. {deleted_count} emails may still be visible.")
    
    logging.info("=" * 50)
    logging.info("OLD EMAIL DELETION PROCESS COMPLETED")
    logging.info("=" * 50)
    
    return deleted_count

def log_email_deletion_summary(deleted_count, cutoff_date_str):
    """
    Log a summary of the email deletion operation.
    
    Args:
        deleted_count (int): Number of emails deleted
        cutoff_date_str (str): Cutoff date used for deletion
    """
    if deleted_count == 0:
        logging.info(f"No emails were deleted (cutoff date: {cutoff_date_str})")
    elif deleted_count == 1:
        logging.info(f"Successfully deleted 1 email older than {cutoff_date_str}")
    else:
        logging.info(f"Successfully deleted {deleted_count} emails older than {cutoff_date_str}")

# =============================================================================
# EMAIL DELETION MECHANISM
# =============================================================================

def delete_email(email_id):
    """
    Delete a single email by marking it for deletion and expunging.
    
    Args:
        email_id (str): IMAP email ID to delete
        
    Returns:
        bool: True if deletion was successful, False otherwise
    """
    global imap_connection
    
    if not ensure_connection():
        logging.error("No active IMAP connection for email deletion")
        return False
    
    try:
        # Mark email for deletion
        result = imap_connection.store(email_id, '+FLAGS', '\\Deleted')
        
        if result[0] != 'OK':
            logging.error(f"Failed to mark email {email_id} for deletion: {result[1]}")
            return False
        
        logging.debug(f"Email {email_id} marked for deletion")
        return True
        
    except imaplib.IMAP4.error as e:
        logging.error(f"IMAP error deleting email {email_id}: {e}")
        return False
    except Exception as e:
        logging.error(f"Unexpected error deleting email {email_id}: {e}")
        return False

def delete_emails_batch(email_ids):
    """
    Delete multiple emails in a batch operation.
    
    Args:
        email_ids (list): List of email IDs to delete
        
    Returns:
        dict: Dictionary with deletion results
    """
    results = {
        'successful': [],
        'failed': [],
        'total': len(email_ids)
    }
    
    if not email_ids:
        logging.info("No emails to delete")
        return results
    
    logging.info(f"Starting deletion of {len(email_ids)} emails")
    
    for email_id in email_ids:
        if delete_email(email_id):
            results['successful'].append(email_id)
        else:
            results['failed'].append(email_id)
    
    # Log batch results
    logging.info(f"Batch deletion completed: {len(results['successful'])} successful, {len(results['failed'])} failed")
    
    return results

def expunge_deleted_emails():
    """
    Permanently remove emails marked for deletion from the server.
    
    Returns:
        bool: True if expunge was successful, False otherwise
    """
    global imap_connection
    
    if not ensure_connection():
        logging.error("No active IMAP connection for expunge operation")
        return False
    
    try:
        logging.info("Expunging deleted emails from server...")
        result = imap_connection.expunge()
        
        if result[0] == 'OK':
            # Count expunged emails
            expunged_count = len([r for r in result[1] if r is not None])
            logging.info(f"Successfully expunged {expunged_count} emails from server")
            return True
        else:
            logging.error(f"Expunge operation failed: {result[1]}")
            return False
            
    except imaplib.IMAP4.error as e:
        logging.error(f"IMAP error during expunge: {e}")
        return False
    except Exception as e:
        logging.error(f"Unexpected error during expunge: {e}")
        return False

def delete_old_emails_with_logging(cutoff_date_str):
    """
    Complete workflow to find, delete, and log old emails.
    
    Args:
        cutoff_date_str (str): Cutoff date in DD-MMM-YYYY format
        
    Returns:
        int: Number of emails successfully deleted
    """
    global operation_summary
    
    logging.info("=" * 50)
    logging.info("STARTING OLD EMAIL DELETION PROCESS")
    logging.info("=" * 50)
    
    # Search for old emails
    old_email_ids = search_old_emails(cutoff_date_str)
    
    if not old_email_ids:
        logging.info("No old emails found to delete")
        return 0
    
    # Validate email IDs
    valid_email_ids = validate_email_ids(old_email_ids)
    
    if not valid_email_ids:
        logging.warning("No valid email IDs found for deletion")
        return 0
    
    # Log emails to be deleted (with metadata)
    logging.info(f"Preparing to delete {len(valid_email_ids)} old emails:")
    
    deleted_count = 0
    
    # Process emails in batches
    for batch_num, email_batch in enumerate(search_emails_batch(valid_email_ids), 1):
        logging.info(f"Processing batch {batch_num} ({len(email_batch)} emails)")
        
        # Get metadata and log details for each email in batch
        for email_id in email_batch:
            metadata = get_email_metadata(email_id)
            
            if metadata:
                # Log email details before deletion
                logging.info(f"Deleting email {email_id}: '{metadata['subject']}' from {metadata['from']} ({metadata['date_str']})")
                
                # Delete the email
                if delete_email(email_id):
                    deleted_count += 1
                    logging.info(f"✓ Successfully deleted email {email_id}")
                else:
                    logging.error(f"✗ Failed to delete email {email_id}")
            else:
                # Still try to delete even if metadata extraction failed
                logging.warning(f"Could not extract metadata for email {email_id}, attempting deletion anyway")
                if delete_email(email_id):
                    deleted_count += 1
                    logging.info(f"✓ Successfully deleted email {email_id} (no metadata)")
                else:
                    logging.error(f"✗ Failed to delete email {email_id}")
    
    # Expunge deleted emails
    if deleted_count > 0:
        if expunge_deleted_emails():
            logging.info(f"All {deleted_count} deleted emails have been permanently removed from server")
        else:
            logging.warning("Some emails may not have been permanently removed due to expunge failure")
    
    # Update operation summary
    operation_summary['emails_deleted'] = deleted_count
    
    logging.info("=" * 50)
    logging.info(f"OLD EMAIL DELETION COMPLETED: {deleted_count} emails deleted")
    logging.info("=" * 50)
    
    return deleted_count

def safe_delete_with_confirmation(email_ids, dry_run=False):
    """
    Safely delete emails with optional dry-run mode for testing.
    
    Args:
        email_ids (list): List of email IDs to delete
        dry_run (bool): If True, only simulate deletion without actually deleting
        
    Returns:
        dict: Results of the deletion operation
    """
    results = {
        'would_delete': len(email_ids),
        'actually_deleted': 0,
        'dry_run': dry_run
    }
    
    if dry_run:
        logging.info(f"DRY RUN: Would delete {len(email_ids)} emails")
        
        # Show what would be deleted
        for email_id in email_ids[:5]:  # Show first 5 as examples
            metadata = get_email_metadata(email_id)
            if metadata:
                logging.info(f"Would delete: '{metadata['subject']}' from {metadata['from']}")
        
        if len(email_ids) > 5:
            logging.info(f"... and {len(email_ids) - 5} more emails")
        
        return results
    
    # Actual deletion
    deletion_results = delete_emails_batch(email_ids)
    results['actually_deleted'] = len(deletion_results['successful'])
    
    if results['actually_deleted'] > 0:
        expunge_deleted_emails()
    
    return results

# =============================================================================
# UNSUBSCRIBE EMAIL PROCESSING
# =============================================================================

def search_unsubscribe_emails():
    """
    Search for emails containing "unsubscribe" in subject or body.
    
    Returns:
        list: List of email IDs containing unsubscribe content
    """
    global imap_connection
    
    if not ensure_connection():
        logging.error("No active IMAP connection for unsubscribe email search")
        return []
    
    try:
        logging.info("Searching for emails containing 'unsubscribe'...")
        
        # Search for "unsubscribe" in subject
        result1, subject_ids = imap_connection.search(None, 'SUBJECT', 'unsubscribe')
        
        # Search for "unsubscribe" in body text
        result2, body_ids = imap_connection.search(None, 'BODY', 'unsubscribe')
        
        if result1 != 'OK' or result2 != 'OK':
            logging.error("Failed to search for unsubscribe emails")
            return []
        
        # Combine and deduplicate results
        all_ids = set()
        
        if subject_ids[0]:
            subject_list = subject_ids[0].split()
            all_ids.update(id.decode() for id in subject_list)
            logging.info(f"Found {len(subject_list)} emails with 'unsubscribe' in subject")
        
        if body_ids[0]:
            body_list = body_ids[0].split()
            all_ids.update(id.decode() for id in body_list)
            logging.info(f"Found {len(body_list)} emails with 'unsubscribe' in body")
        
        unique_ids = list(all_ids)
        logging.info(f"Total unique unsubscribe emails found: {len(unique_ids)}")
        
        return unique_ids
        
    except imaplib.IMAP4.error as e:
        logging.error(f"IMAP error searching for unsubscribe emails: {e}")
        return []
    except Exception as e:
        logging.error(f"Unexpected error searching for unsubscribe emails: {e}")
        return []

def get_email_content(email_id):
    """
    Extract the full content of an email for link processing.
    
    Args:
        email_id (str): IMAP email ID
        
    Returns:
        str: Email content as text, or empty string if extraction fails
    """
    global imap_connection
    
    if not ensure_connection():
        logging.error("No active IMAP connection for content extraction")
        return ""
    
    try:
        # Fetch full email
        result, email_data = imap_connection.fetch(email_id, '(RFC822)')
        
        if result != 'OK':
            logging.warning(f"Failed to fetch email content for {email_id}")
            return ""
        
        # Parse email message
        email_message = email.message_from_bytes(email_data[0][1])
        
        # Extract text content
        content = ""
        
        if email_message.is_multipart():
            # Handle multipart emails
            for part in email_message.walk():
                content_type = part.get_content_type()
                if content_type in ['text/plain', 'text/html']:
                    try:
                        payload = part.get_payload(decode=True)
                        if payload:
                            content += payload.decode('utf-8', errors='ignore') + "\n"
                    except Exception as e:
                        logging.debug(f"Error decoding email part: {e}")
        else:
            # Handle single-part emails
            try:
                payload = email_message.get_payload(decode=True)
                if payload:
                    content = payload.decode('utf-8', errors='ignore')
            except Exception as e:
                logging.debug(f"Error decoding email content: {e}")
        
        return content
        
    except Exception as e:
        logging.warning(f"Error extracting content for email {email_id}: {e}")
        return ""

def process_unsubscribe_emails():
    """
    Complete workflow to find and process unsubscribe emails.
    
    Returns:
        list: List of email IDs that contain unsubscribe content
    """
    global operation_summary
    
    logging.info("=" * 50)
    logging.info("STARTING UNSUBSCRIBE EMAIL SEARCH")
    logging.info("=" * 50)
    
    # Search for unsubscribe emails
    unsubscribe_email_ids = search_unsubscribe_emails()
    
    if not unsubscribe_email_ids:
        logging.info("No unsubscribe emails found")
        operation_summary['unsubscribe_emails_found'] = 0
        return []
    
    # Validate email IDs
    valid_email_ids = validate_email_ids(unsubscribe_email_ids)
    
    if not valid_email_ids:
        logging.warning("No valid unsubscribe email IDs found")
        operation_summary['unsubscribe_emails_found'] = 0
        return []
    
    # Log found emails with metadata
    logging.info(f"Processing {len(valid_email_ids)} unsubscribe emails:")
    
    processed_emails = []
    
    for email_id in valid_email_ids:
        metadata = get_email_metadata(email_id)
        
        if metadata:
            logging.info(f"Unsubscribe email {email_id}: '{metadata['subject']}' from {metadata['from']}")
            processed_emails.append(email_id)
        else:
            logging.warning(f"Could not extract metadata for unsubscribe email {email_id}")
            processed_emails.append(email_id)  # Still include it for processing
    
    # Update operation summary
    operation_summary['unsubscribe_emails_found'] = len(processed_emails)
    
    logging.info("=" * 50)
    logging.info(f"UNSUBSCRIBE EMAIL SEARCH COMPLETED: {len(processed_emails)} emails found")
    logging.info("=" * 50)
    
    return processed_emails

# =============================================================================
# UNSUBSCRIBE LINK EXTRACTION
# =============================================================================

def extract_unsubscribe_links(email_content):
    """
    Extract unsubscribe URLs from email content using regex.
    
    Args:
        email_content (str): Email content as text
        
    Returns:
        list: List of unique unsubscribe URLs found
    """
    if not email_content:
        return []
    
    try:
        # Use the global regex pattern for unsubscribe links
        matches = re.findall(UNSUBSCRIBE_REGEX, email_content, re.IGNORECASE)
        
        # Remove duplicates and clean up URLs
        unique_links = []
        seen_links = set()
        
        for match in matches:
            # Clean up the URL (remove trailing punctuation, etc.)
            cleaned_url = match.rstrip('.,;!?)')
            
            # Validate URL format
            if is_valid_unsubscribe_url(cleaned_url) and cleaned_url not in seen_links:
                unique_links.append(cleaned_url)
                seen_links.add(cleaned_url)
        
        return unique_links
        
    except Exception as e:
        logging.warning(f"Error extracting unsubscribe links: {e}")
        return []

def is_valid_unsubscribe_url(url):
    """
    Validate that a URL is a proper unsubscribe link.
    
    Args:
        url (str): URL to validate
        
    Returns:
        bool: True if URL appears to be a valid unsubscribe link
    """
    if not url or len(url) < 10:
        return False
    
    # Must start with http or https
    if not url.lower().startswith(('http://', 'https://')):
        return False
    
    # Must contain 'unsubscribe' (case insensitive)
    if 'unsubscribe' not in url.lower():
        return False
    
    # Should not contain suspicious patterns
    suspicious_patterns = ['javascript:', 'data:', 'file:', 'ftp:']
    if any(pattern in url.lower() for pattern in suspicious_patterns):
        return False
    
    return True

def extract_links_from_email(email_id):
    """
    Extract unsubscribe links from a specific email.
    
    Args:
        email_id (str): IMAP email ID
        
    Returns:
        dict: Dictionary with email info and extracted links
    """
    # Get email metadata
    metadata = get_email_metadata(email_id)
    if not metadata:
        logging.warning(f"Could not get metadata for email {email_id}")
        return None
    
    # Get email content
    content = get_email_content(email_id)
    if not content:
        logging.warning(f"Could not get content for email {email_id}")
        return {
            'email_id': email_id,
            'subject': metadata.get('subject', 'Unknown'),
            'from': metadata.get('from', 'Unknown'),
            'links': []
        }
    
    # Extract unsubscribe links
    links = extract_unsubscribe_links(content)
    
    return {
        'email_id': email_id,
        'subject': metadata.get('subject', 'Unknown'),
        'from': metadata.get('from', 'Unknown'),
        'links': links,
        'content_length': len(content)
    }

def process_unsubscribe_links(email_ids):
    """
    Process multiple emails to extract all unsubscribe links.
    
    Args:
        email_ids (list): List of email IDs to process
        
    Returns:
        dict: Dictionary with processing results
    """
    results = {
        'emails_processed': 0,
        'emails_with_links': 0,
        'total_links_found': 0,
        'unique_links': set(),
        'email_details': []
    }
    
    if not email_ids:
        logging.info("No emails to process for unsubscribe links")
        return results
    
    logging.info(f"Extracting unsubscribe links from {len(email_ids)} emails...")
    
    for email_id in email_ids:
        try:
            email_data = extract_links_from_email(email_id)
            
            if email_data:
                results['emails_processed'] += 1
                
                if email_data['links']:
                    results['emails_with_links'] += 1
                    results['total_links_found'] += len(email_data['links'])
                    
                    # Add to unique links set
                    for link in email_data['links']:
                        results['unique_links'].add(link)
                    
                    # Log found links
                    logging.info(f"Email '{email_data['subject'][:50]}...' from {email_data['from']}: {len(email_data['links'])} links")
                    for link in email_data['links']:
                        logging.info(f"  → {link}")
                else:
                    logging.debug(f"No unsubscribe links found in email {email_id}")
                
                results['email_details'].append(email_data)
            
        except Exception as e:
            logging.error(f"Error processing email {email_id} for links: {e}")
    
    # Convert set to list for easier handling
    results['unique_links'] = list(results['unique_links'])
    
    # Log summary
    logging.info(f"Link extraction completed:")
    logging.info(f"  Emails processed: {results['emails_processed']}")
    logging.info(f"  Emails with links: {results['emails_with_links']}")
    logging.info(f"  Total links found: {results['total_links_found']}")
    logging.info(f"  Unique links: {len(results['unique_links'])}")
    
    return results

def validate_and_clean_links(links):
    """
    Validate and clean a list of unsubscribe links.
    
    Args:
        links (list): List of URLs to validate and clean
        
    Returns:
        list: List of validated and cleaned URLs
    """
    cleaned_links = []
    
    for link in links:
        if is_valid_unsubscribe_url(link):
            # Additional cleaning
            cleaned_link = link.strip()
            
            # Remove common tracking parameters that might cause issues
            tracking_params = ['utm_source', 'utm_medium', 'utm_campaign', 'utm_content', 'utm_term']
            
            # Simple parameter removal (basic implementation)
            if '?' in cleaned_link:
                base_url, params = cleaned_link.split('?', 1)
                param_pairs = params.split('&')
                filtered_params = []
                
                for param in param_pairs:
                    if '=' in param:
                        param_name = param.split('=')[0]
                        if param_name not in tracking_params:
                            filtered_params.append(param)
                
                if filtered_params:
                    cleaned_link = base_url + '?' + '&'.join(filtered_params)
                else:
                    cleaned_link = base_url
            
            cleaned_links.append(cleaned_link)
        else:
            logging.warning(f"Invalid unsubscribe URL filtered out: {link}")
    
    return cleaned_links

def log_extracted_links(links):
    """
    Log extracted unsubscribe links in a formatted way.
    
    Args:
        links (list): List of unsubscribe URLs
    """
    if not links:
        logging.info("No unsubscribe links extracted")
        return
    
    logging.info("=" * 50)
    logging.info("EXTRACTED UNSUBSCRIBE LINKS")
    logging.info("=" * 50)
    
    for i, link in enumerate(links, 1):
        logging.info(f"{i:2d}. {link}")
    
    logging.info("=" * 50)

# =============================================================================
# UNSUBSCRIBE REQUEST FUNCTIONALITY
# =============================================================================

def send_unsubscribe_request(url):
    """
    Send a GET request to an unsubscribe URL.
    
    Args:
        url (str): Unsubscribe URL to request
        
    Returns:
        dict: Dictionary with request results
    """
    result = {
        'url': url,
        'success': False,
        'status_code': None,
        'error': None,
        'response_time': None
    }
    
    try:
        start_time = time.time()
        
        # Set up headers to mimic a real browser
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        # Send GET request with timeout
        response = requests.get(
            url, 
            headers=headers, 
            timeout=HTTP_TIMEOUT,
            allow_redirects=True,
            verify=True  # Verify SSL certificates
        )
        
        end_time = time.time()
        result['response_time'] = round(end_time - start_time, 2)
        result['status_code'] = response.status_code
        
        # Consider 2xx and 3xx status codes as success
        if 200 <= response.status_code < 400:
            result['success'] = True
            logging.info(f"✓ Unsubscribe request successful: {url} (Status: {response.status_code})")
        else:
            result['error'] = f"HTTP {response.status_code}"
            logging.warning(f"✗ Unsubscribe request failed: {url} (Status: {response.status_code})")
        
    except requests.exceptions.Timeout:
        result['error'] = "Request timeout"
        logging.warning(f"✗ Unsubscribe request timed out: {url}")
    except requests.exceptions.ConnectionError:
        result['error'] = "Connection error"
        logging.warning(f"✗ Connection error for unsubscribe request: {url}")
    except requests.exceptions.SSLError:
        result['error'] = "SSL error"
        logging.warning(f"✗ SSL error for unsubscribe request: {url}")
    except requests.exceptions.RequestException as e:
        result['error'] = str(e)
        logging.warning(f"✗ Request error for unsubscribe: {url} - {e}")
    except Exception as e:
        result['error'] = f"Unexpected error: {e}"
        logging.error(f"✗ Unexpected error sending unsubscribe request to {url}: {e}")
    
    return result

def send_unsubscribe_requests_batch(urls):
    """
    Send unsubscribe requests to multiple URLs with rate limiting.
    
    Args:
        urls (list): List of unsubscribe URLs
        
    Returns:
        dict: Dictionary with batch processing results
    """
    results = {
        'total_requests': len(urls),
        'successful_requests': 0,
        'failed_requests': 0,
        'request_details': [],
        'errors': {}
    }
    
    if not urls:
        logging.info("No unsubscribe URLs to process")
        return results
    
    logging.info(f"Sending unsubscribe requests to {len(urls)} URLs...")
    logging.info(f"Request delay: {REQUEST_DELAY} seconds between requests")
    
    for i, url in enumerate(urls, 1):
        logging.info(f"Processing unsubscribe request {i}/{len(urls)}: {url}")
        
        # Send the request
        request_result = send_unsubscribe_request(url)
        results['request_details'].append(request_result)
        
        if request_result['success']:
            results['successful_requests'] += 1
        else:
            results['failed_requests'] += 1
            
            # Track error types
            error_type = request_result['error'] or 'Unknown error'
            if error_type not in results['errors']:
                results['errors'][error_type] = 0
            results['errors'][error_type] += 1
        
        # Rate limiting - wait between requests (except for the last one)
        if i < len(urls):
            logging.debug(f"Waiting {REQUEST_DELAY} seconds before next request...")
            time.sleep(REQUEST_DELAY)
    
    # Log batch summary
    logging.info("=" * 50)
    logging.info("UNSUBSCRIBE REQUEST SUMMARY")
    logging.info("=" * 50)
    logging.info(f"Total requests sent: {results['total_requests']}")
    logging.info(f"Successful requests: {results['successful_requests']}")
    logging.info(f"Failed requests: {results['failed_requests']}")
    
    if results['errors']:
        logging.info("Error breakdown:")
        for error_type, count in results['errors'].items():
            logging.info(f"  {error_type}: {count}")
    
    logging.info("=" * 50)
    
    return results

def confirm_unsubscribe_requests(urls):
    """
    Ask user for confirmation before sending unsubscribe requests.
    
    Args:
        urls (list): List of URLs to send requests to
        
    Returns:
        bool: True if user confirms, False otherwise
    """
    if not urls:
        return False
    
    print("\n" + "=" * 60)
    print("UNSUBSCRIBE REQUEST CONFIRMATION")
    print("=" * 60)
    print(f"Found {len(urls)} unsubscribe links to process:")
    
    # Show first few URLs as examples
    for i, url in enumerate(urls[:5], 1):
        print(f"{i:2d}. {url}")
    
    if len(urls) > 5:
        print(f"    ... and {len(urls) - 5} more URLs")
    
    print("\nWARNING: This will send HTTP GET requests to these URLs.")
    print("This action cannot be undone.")
    print(f"Requests will be sent with {REQUEST_DELAY} second delays between them.")
    
    while True:
        response = input("\nProceed with sending unsubscribe requests? (y/n): ").lower().strip()
        if response in ['y', 'yes']:
            return True
        elif response in ['n', 'no']:
            return False
        else:
            print("Please enter 'y' for yes or 'n' for no.")

def process_unsubscribe_workflow(email_ids):
    """
    Complete workflow for processing unsubscribe emails and sending requests.
    
    Args:
        email_ids (list): List of email IDs containing unsubscribe content
        
    Returns:
        dict: Dictionary with complete workflow results
    """
    global operation_summary
    
    workflow_results = {
        'emails_processed': 0,
        'links_extracted': 0,
        'requests_sent': 0,
        'successful_unsubscribes': 0,
        'failed_unsubscribes': 0
    }
    
    if not email_ids:
        logging.info("No unsubscribe emails to process")
        return workflow_results
    
    # Extract links from emails
    logging.info("Extracting unsubscribe links from emails...")
    link_results = process_unsubscribe_links(email_ids)
    
    workflow_results['emails_processed'] = link_results['emails_processed']
    workflow_results['links_extracted'] = len(link_results['unique_links'])
    
    if not link_results['unique_links']:
        logging.info("No unsubscribe links found to process")
        return workflow_results
    
    # Validate and clean links
    cleaned_links = validate_and_clean_links(link_results['unique_links'])
    log_extracted_links(cleaned_links)
    
    if not cleaned_links:
        logging.info("No valid unsubscribe links after cleaning")
        return workflow_results
    
    # Ask for user confirmation
    if not confirm_unsubscribe_requests(cleaned_links):
        logging.info("Unsubscribe requests cancelled by user")
        return workflow_results
    
    # Send unsubscribe requests
    request_results = send_unsubscribe_requests_batch(cleaned_links)
    
    workflow_results['requests_sent'] = request_results['total_requests']
    workflow_results['successful_unsubscribes'] = request_results['successful_requests']
    workflow_results['failed_unsubscribes'] = request_results['failed_requests']
    
    # Update global operation summary
    operation_summary['unsubscribe_links_processed'] = workflow_results['links_extracted']
    operation_summary['successful_unsubscribes'] = workflow_results['successful_unsubscribes']
    operation_summary['failed_unsubscribes'] = workflow_results['failed_unsubscribes']
    
    return workflow_results

# =============================================================================
# USER INPUT AND CONFIGURATION
# =============================================================================

def get_user_input():
    """
    Interactively get configuration from user instead of hard-coding.
    
    Returns:
        dict: Configuration dictionary with user inputs
    """
    import getpass
    
    print("=" * 60)
    print("Gmail IMAP Cleaner - Configuration Setup")
    print("=" * 60)
    
    config = {}
    
    # Get email address
    while True:
        email = input("Enter your Gmail address: ").strip()
        if email and '@' in email:
            config['email'] = email
            break
        else:
            print("Please enter a valid email address.")
    
    # Get password securely
    while True:
        password = getpass.getpass("Enter your Gmail password or app password: ").strip()
        if password:
            config['password'] = password
            break
        else:
            print("Password cannot be empty.")
    
    # Get cutoff date
    while True:
        cutoff_date = input("Enter cutoff date for old emails (DD-MMM-YYYY, e.g., 01-Jul-2023): ").strip()
        if validate_date_format(cutoff_date):
            config['cutoff_date'] = cutoff_date
            break
        else:
            print("Please enter date in DD-MMM-YYYY format (e.g., 01-Jul-2023).")
    
    # Ask about operations to perform
    print("\nSelect operations to perform:")
    config['delete_old'] = input("Delete old emails? (y/n): ").lower().startswith('y')
    config['process_unsubscribe'] = input("Process unsubscribe emails? (y/n): ").lower().startswith('y')
    
    if config['delete_old']:
        config['dry_run'] = input("Perform dry run first (recommended)? (y/n): ").lower().startswith('y')
    else:
        config['dry_run'] = False
    
    print("\nConfiguration Summary:")
    print(f"Email: {config['email']}")
    print(f"Cutoff Date: {config['cutoff_date']}")
    print(f"Delete Old Emails: {'Yes' if config['delete_old'] else 'No'}")
    print(f"Process Unsubscribe: {'Yes' if config['process_unsubscribe'] else 'No'}")
    if config['delete_old']:
        print(f"Dry Run: {'Yes' if config['dry_run'] else 'No'}")
    
    confirm = input("\nProceed with these settings? (y/n): ").lower().startswith('y')
    if not confirm:
        print("Configuration cancelled.")
        return None
    
    return config

# =============================================================================
# MAIN EXECUTION PLACEHOLDER
# =============================================================================

def main():
    """
    Main function that orchestrates all email management operations.
    """
    # Setup logging
    setup_logging()
    
    logging.info("Starting Gmail IMAP Cleaner")
    
    # Get configuration from user
    config = get_user_input()
    if config is None:
        logging.info("Script cancelled by user")
        return False
    
    # Update global variables with user input
    global EMAIL, PASSWORD, CUTOFF_DATE
    EMAIL = config['email']
    PASSWORD = config['password']
    CUTOFF_DATE = config['cutoff_date']
    
    logging.info(f"Target email: {EMAIL}")
    logging.info(f"Cutoff date: {CUTOFF_DATE}")
    
    # Test date functions
    if not test_date_functions():
        logging.error("Date function tests failed. Please check the implementation.")
        return False
    
    # Get and log date range information
    date_info = get_date_range_info(CUTOFF_DATE)
    if date_info is None:
        logging.error("Failed to parse cutoff date. Please check the CUTOFF_DATE format.")
        return False
    
    if date_info['is_future_date']:
        logging.warning(f"Cutoff date {CUTOFF_DATE} is in the future. No emails will be deleted.")
    else:
        logging.info(f"Will delete emails older than {date_info['days_difference']} days (before {CUTOFF_DATE})")
    
    try:
        # Connect to Gmail IMAP
        if not connect_to_gmail():
            logging.error("Failed to connect to Gmail. Please check your credentials and network connection.")
            return False
        
        # Process old emails if requested
        if config['delete_old']:
            if config['dry_run']:
                logging.info("Performing DRY RUN - no emails will actually be deleted")
                old_email_ids = search_old_emails(CUTOFF_DATE)
                safe_delete_with_confirmation(old_email_ids, dry_run=True)
                
                proceed = input("\nProceed with actual deletion? (y/n): ").lower().startswith('y')
                if proceed:
                    delete_old_emails_with_logging(CUTOFF_DATE)
                else:
                    logging.info("Email deletion cancelled by user")
            else:
                delete_old_emails_with_logging(CUTOFF_DATE)
        
        # Process unsubscribe emails if requested
        if config['process_unsubscribe']:
            unsubscribe_emails = process_unsubscribe_emails()
            
            if unsubscribe_emails:
                # Complete unsubscribe workflow (extract links and send requests)
                unsubscribe_results = process_unsubscribe_workflow(unsubscribe_emails)
                
                # Log workflow summary
                logging.info("Unsubscribe processing completed:")
                logging.info(f"  Emails processed: {unsubscribe_results['emails_processed']}")
                logging.info(f"  Links extracted: {unsubscribe_results['links_extracted']}")
                logging.info(f"  Requests sent: {unsubscribe_results['requests_sent']}")
                logging.info(f"  Successful unsubscribes: {unsubscribe_results['successful_unsubscribes']}")
                logging.info(f"  Failed unsubscribes: {unsubscribe_results['failed_unsubscribes']}")
            else:
                logging.info("No unsubscribe emails found to process")
        
        logging.info("All operations completed successfully")
        
    except Exception as e:
        logging.error(f"Error during email processing: {e}")
        return False
    
    finally:
        # Always attempt to disconnect cleanly
        disconnect_from_gmail()
        
        # Log operation summary
        log_operation_summary()
    
    logging.info("Gmail IMAP Cleaner completed")
    return True

if __name__ == "__main__":
    try:
        success = main()
        exit(0 if success else 1)
    except KeyboardInterrupt:
        logging.info("Script interrupted by user")
        exit(1)
    except Exception as e:
        logging.error(f"Unexpected error: {e}")
        exit(1)